#!/home/junsoo/miniconda3/bin/python
"""
bsr - lightweight SBATCH launcher
Example
-------
# one A100 for 3-days, run train.sh
bsr a1 1 -time 03-00:00:00 -jobname train -cmd "bash train.sh"

# With specific node
bsr a1 2 tomato -time 03-00:00:00 -jobname train -cmd "bash train.sh"

# Available prefixes:
# r3: RTX3090, r2: RTX2080, ad: ADA, a1: A100, h1: H100, ti: TITAN, de: dept
"""
import argparse
import os
import subprocess
import tempfile
import textwrap

parser = argparse.ArgumentParser()
parser.add_argument("prefix", type=str,
                    help="Partition prefix (r3, r2, ad, a1, h1, ti, de)")
parser.add_argument("gpu_count", type=int,
                    help="Number of GPUs")
parser.add_argument("nodelist", type=str, nargs='?', default="all",
                    help="Specific node or 'all' (optional)")
parser.add_argument("-time", type=str, default="04-00:00:00",
                    help="Wall-time DD-HH:MM:SS")
parser.add_argument("-qos", type=str, default="normal",
                    help="QOS name")
parser.add_argument("-j", "--jobname", type=str, default="bsr",
                    help="Job name")
parser.add_argument("-c", "--cmd", type=str, default="bash -l",
                    help="Command executed inside the job")
parser.add_argument("--dry-run", action="store_true",
                    help="Print script instead of submitting")

args = parser.parse_args()

# Map prefix to Slurm partition (same as first file)
prefix_map = {
    "r3": "rtx3090",
    "r2": "rtx2080", 
    "ad": "ada",
    "a1": "a100",
    "h1": "h100",
    "ti": "titan",
    "de": "dept"
}

if args.prefix not in prefix_map:
    print(f"Error: Unknown prefix '{args.prefix}'")
    print("Valid prefixes: r3, r2, ad, a1, h1, ti, de")
    exit(1)

partition = prefix_map[args.prefix]

# Default per-GPU resources (same as first file)
CPU_PER_GPU = 10
MEM_PER_GPU = 60  # in GB

# Calculate total resources based on GPU count
total_cpus = args.gpu_count * CPU_PER_GPU
total_mem_gb = args.gpu_count * MEM_PER_GPU
total_mem_mb = total_mem_gb * 1024  # Convert to MB for SBATCH

# Adding time printing
args.cmd = f'echo "[INFO] Job started at : $(date) on $(hostname)"\necho "[INFO] Running command: {args.cmd}"\n\n{args.cmd}\n\necho "[INFO] Job finished at: $(date) on $(hostname)"'

# ---------- build SBATCH header ----------
sbatch_lines = []
sbatch_lines.append(f"#SBATCH --cpus-per-task={total_cpus}")
sbatch_lines.append(f"#SBATCH --gres=gpu:{args.gpu_count}")
sbatch_lines.append(f"#SBATCH --mem={total_mem_mb}")
if args.nodelist != "all":
    sbatch_lines.append(f"#SBATCH --nodelist={args.nodelist}")
sbatch_lines.append(f"#SBATCH --partition={partition}")
sbatch_lines.append(f"#SBATCH --time={args.time}")
sbatch_lines.append(f"#SBATCH --qos={args.qos}")
sbatch_lines.append(f"#SBATCH --job-name={args.jobname}")

joined = '\n'.join(sbatch_lines)

# ---------- assemble complete script ----------
script_text = textwrap.dedent(f"""#!/bin/bash
{joined}
#SBATCH --output=slurm-%x-%j.out

set -euo pipefail

{args.cmd}
""")

# ---------- dryâ€‘run or submit ----------
if args.dry_run:
    print(script_text)
    exit(0)

with tempfile.NamedTemporaryFile("w", delete=False, suffix=".sbatch") as tf:
    tf.write(script_text)
    script_path = tf.name

print("Submitting job with the following SBATCH script:\n")
print(script_text)
subprocess.run(["sbatch", script_path], check=True)